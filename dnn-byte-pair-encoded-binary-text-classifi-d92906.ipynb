{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":2233682,"sourceType":"datasetVersion","datasetId":1340369}],"dockerImageVersionId":30475,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tokenizers","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:02:30.690999Z","iopub.execute_input":"2023-11-15T03:02:30.691363Z","iopub.status.idle":"2023-11-15T03:02:37.101116Z","shell.execute_reply.started":"2023-11-15T03:02:30.691337Z","shell.execute_reply":"2023-11-15T03:02:37.100130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom tokenizers import ByteLevelBPETokenizer\nimport pickle\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:02:37.102761Z","iopub.execute_input":"2023-11-15T03:02:37.103009Z","iopub.status.idle":"2023-11-15T03:03:18.676252Z","shell.execute_reply.started":"2023-11-15T03:02:37.102985Z","shell.execute_reply":"2023-11-15T03:03:18.674960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use a TPU / GPU if available","metadata":{}},{"cell_type":"code","source":"# Detect and init the TPU if available\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\n    master = tpu.master()\n    print('Running on TPU:', master if master else 'local')\nexcept ValueError:\n    # If a TPU is not available, check for a GPU\n    if tf.config.list_physical_devices('GPU'):\n        strategy = tf.distribute.OneDeviceStrategy(\"GPU\")\n        print('Running on GPU')\n    else:\n        strategy = tf.distribute.OneDeviceStrategy(\"CPU\")\n        print('Running on CPU')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:03:18.677714Z","iopub.execute_input":"2023-11-15T03:03:18.678313Z","iopub.status.idle":"2023-11-15T03:03:27.015311Z","shell.execute_reply.started":"2023-11-15T03:03:18.678280Z","shell.execute_reply":"2023-11-15T03:03:27.014390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data and data preprocessing","metadata":{}},{"cell_type":"code","source":"# Load the data\ndata = pd.read_csv(\"/kaggle/input/amazon-reviews/train.csv\", header=None)\ntest_data = pd.read_csv('/kaggle/input/amazon-reviews/test.csv', header=None)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:03:27.017178Z","iopub.execute_input":"2023-11-15T03:03:27.017420Z","iopub.status.idle":"2023-11-15T03:04:07.788306Z","shell.execute_reply.started":"2023-11-15T03:03:27.017397Z","shell.execute_reply":"2023-11-15T03:04:07.787189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the data\ndf = pd.DataFrame(columns=[\"rating\", \"review\"])\n\ndf[\"rating\"] = data[0].apply(lambda x: x - 1)\ndf[\"review\"] = data[1] + \" \" + data[2]\n\ntest_df = pd.DataFrame(columns=[\"rating\", \"review\"])\n\ntest_df[\"rating\"] = test_data[0].apply(lambda x: x - 1)\ntest_df[\"review\"] = test_data[1] + \" \" + test_data[2]","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:04:07.789416Z","iopub.execute_input":"2023-11-15T03:04:07.789868Z","iopub.status.idle":"2023-11-15T03:04:13.694428Z","shell.execute_reply.started":"2023-11-15T03:04:07.789843Z","shell.execute_reply":"2023-11-15T03:04:13.693493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect the data\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:04:13.695395Z","iopub.execute_input":"2023-11-15T03:04:13.695656Z","iopub.status.idle":"2023-11-15T03:04:13.709618Z","shell.execute_reply.started":"2023-11-15T03:04:13.695635Z","shell.execute_reply":"2023-11-15T03:04:13.708793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)\ntest_df.dropna(inplace=True)\n\ndf = df.sample(1_200_000, random_state=42)\ntest_df = test_df.sample(100_000, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:04:13.710500Z","iopub.execute_input":"2023-11-15T03:04:13.710766Z","iopub.status.idle":"2023-11-15T03:04:14.964012Z","shell.execute_reply.started":"2023-11-15T03:04:13.710746Z","shell.execute_reply":"2023-11-15T03:04:14.963009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:04:14.965798Z","iopub.execute_input":"2023-11-15T03:04:14.966074Z","iopub.status.idle":"2023-11-15T03:04:14.977357Z","shell.execute_reply.started":"2023-11-15T03:04:14.966052Z","shell.execute_reply":"2023-11-15T03:04:14.976676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"# Instantiate the tokenizer\nsequence_length = 512\nvocab_size = 50000\n\ntokenizer = ByteLevelBPETokenizer()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:04:14.978493Z","iopub.execute_input":"2023-11-15T03:04:14.978789Z","iopub.status.idle":"2023-11-15T03:04:14.988701Z","shell.execute_reply.started":"2023-11-15T03:04:14.978765Z","shell.execute_reply":"2023-11-15T03:04:14.987934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.train_from_iterator(df['review'], vocab_size=vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:04:14.991615Z","iopub.execute_input":"2023-11-15T03:04:14.991846Z","iopub.status.idle":"2023-11-15T03:04:49.758811Z","shell.execute_reply.started":"2023-11-15T03:04:14.991827Z","shell.execute_reply":"2023-11-15T03:04:49.757915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the sequences\ndf['encoded_sequence'] = [tokenizer.encode(review).ids for review in df['review']]\ntest_df['encoded_sequence'] = [tokenizer.encode(review).ids for review in test_df['review']]","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:04:49.776372Z","iopub.execute_input":"2023-11-15T03:04:49.776666Z","iopub.status.idle":"2023-11-15T03:11:53.717431Z","shell.execute_reply.started":"2023-11-15T03:04:49.776643Z","shell.execute_reply":"2023-11-15T03:11:53.716236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(df['encoded_sequence'].apply(len))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:11:53.718847Z","iopub.execute_input":"2023-11-15T03:11:53.719227Z","iopub.status.idle":"2023-11-15T03:11:54.212914Z","shell.execute_reply.started":"2023-11-15T03:11:53.719190Z","shell.execute_reply":"2023-11-15T03:11:54.211789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['padded_sequence'] = tf.keras.preprocessing.sequence.pad_sequences(df['encoded_sequence'], maxlen=sequence_length, padding='post').tolist()\ntest_df['padded_sequence'] = tf.keras.preprocessing.sequence.pad_sequences(test_df['encoded_sequence'], maxlen=sequence_length, padding='post').tolist()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:11:54.214169Z","iopub.execute_input":"2023-11-15T03:11:54.214467Z","iopub.status.idle":"2023-11-15T03:12:31.452096Z","shell.execute_reply.started":"2023-11-15T03:11:54.214443Z","shell.execute_reply":"2023-11-15T03:12:31.450935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:12:31.453316Z","iopub.execute_input":"2023-11-15T03:12:31.453625Z","iopub.status.idle":"2023-11-15T03:12:31.499982Z","shell.execute_reply.started":"2023-11-15T03:12:31.453601Z","shell.execute_reply":"2023-11-15T03:12:31.498750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = tokenizer.get_vocab_size()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:12:31.501209Z","iopub.execute_input":"2023-11-15T03:12:31.501494Z","iopub.status.idle":"2023-11-15T03:12:31.545607Z","shell.execute_reply.started":"2023-11-15T03:12:31.501472Z","shell.execute_reply":"2023-11-15T03:12:31.544402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model architechure","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    # Model architecture\n    model = tf.keras.Sequential([\n        tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=300, mask_zero=True),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n        tf.keras.layers.BatchNormalization(),\n\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n        tf.keras.layers.BatchNormalization(),\n\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n        tf.keras.layers.BatchNormalization(),\n\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n        tf.keras.layers.BatchNormalization(),\n\n        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.5), # we're using a dropout of 50% here to introduce a significant amount of regularization and to encourage the model to learn more robust and generalizable features\n\n        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n        tf.keras.layers.BatchNormalization(),\n\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n                  optimizer=tf.keras.optimizers.Adam(1e-3),\n                  metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:12:31.550582Z","iopub.execute_input":"2023-11-15T03:12:31.550881Z","iopub.status.idle":"2023-11-15T03:12:42.917726Z","shell.execute_reply.started":"2023-11-15T03:12:31.550857Z","shell.execute_reply":"2023-11-15T03:12:42.916410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training","metadata":{}},{"cell_type":"markdown","source":"Here, we convert all of our data to NumPy arrays, subsequently making all of them them contiguous as well as setting the writeable flag to False.\nWe do this because we are aiming to optimize memory usage, improve data access efficiency, and ensure the data is not accidentally modified during the execution of subsequent code.","metadata":{}},{"cell_type":"code","source":"X_train = np.array(df['padded_sequence'].tolist())\nX_train = np.ascontiguousarray(X_train)\nX_train.flags.writeable = False\n\ny_train = np.array(df['rating'].tolist())\ny_train = np.ascontiguousarray(y_train)\ny_train.flags.writeable = False\n\nX_test = np.array(test_df['padded_sequence'].tolist())\nX_test = np.ascontiguousarray(X_test)\nX_test.flags.writeable = False\n\ny_test = np.array(test_df['rating'].tolist())\ny_test = np.ascontiguousarray(y_test)\ny_test.flags.writeable = False","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:12:42.919009Z","iopub.execute_input":"2023-11-15T03:12:42.919291Z","iopub.status.idle":"2023-11-15T03:13:29.599702Z","shell.execute_reply.started":"2023-11-15T03:12:42.919267Z","shell.execute_reply":"2023-11-15T03:13:29.598446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=1, batch_size=64,\n                    validation_data=(X_test, y_test),\n                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:13:29.600961Z","iopub.execute_input":"2023-11-15T03:13:29.601278Z","iopub.status.idle":"2023-11-15T03:58:56.321044Z","shell.execute_reply.started":"2023-11-15T03:13:29.601250Z","shell.execute_reply":"2023-11-15T03:58:56.319695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model evaluation","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:58:56.323794Z","iopub.execute_input":"2023-11-15T03:58:56.324657Z","iopub.status.idle":"2023-11-15T04:01:43.722690Z","shell.execute_reply.started":"2023-11-15T03:58:56.324605Z","shell.execute_reply":"2023-11-15T04:01:43.721594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install seaborn","metadata":{"execution":{"iopub.status.busy":"2023-11-15T04:01:43.723930Z","iopub.execute_input":"2023-11-15T04:01:43.724224Z","iopub.status.idle":"2023-11-15T04:01:49.039334Z","shell.execute_reply.started":"2023-11-15T04:01:43.724199Z","shell.execute_reply":"2023-11-15T04:01:49.038131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Assuming you have predictions from your model\ny_pred = model.predict(X_test)\n\n# Convert the predicted probabilities to class labels\ny_pred_labels = np.argmax(y_pred, axis=1)\n \n# Create the confusion matrix\ncm = confusion_matrix(y_test, y_pred_labels)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T04:01:49.040885Z","iopub.execute_input":"2023-11-15T04:01:49.041323Z","iopub.status.idle":"2023-11-15T04:03:40.416924Z","shell.execute_reply.started":"2023-11-15T04:01:49.041294Z","shell.execute_reply":"2023-11-15T04:03:40.415880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting the loss, value loss, accuracy and value accuracy","metadata":{}},{"cell_type":"code","source":"metrics = history.history\nplt.figure(figsize=(16,6))\nplt.subplot(1,2,1)\nplt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.ylim([0, max(plt.ylim())])\nplt.xlabel('Epoch')\nplt.ylabel('Loss [BinaryCrossEntropy]')\n\nplt.subplot(1,2,2)\nplt.plot(history.epoch, 100 * np.array(metrics['accuracy']), 100 * np.array(metrics['val_accuracy']))\nplt.legend(['accuracy', 'val_accuracy'])\nplt.ylim([0, 100])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy [%]')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T04:03:40.418089Z","iopub.execute_input":"2023-11-15T04:03:40.418391Z","iopub.status.idle":"2023-11-15T04:03:40.753219Z","shell.execute_reply.started":"2023-11-15T04:03:40.418364Z","shell.execute_reply":"2023-11-15T04:03:40.752293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{}},{"cell_type":"code","source":"# Save the model\nmodel.save('/kaggle/working/model.h5')\n\n# Save the tokenizer\ntokenizer.save('/kaggle/working/tokenizer.bpe')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T04:03:40.754225Z","iopub.execute_input":"2023-11-15T04:03:40.754498Z","iopub.status.idle":"2023-11-15T04:03:41.692821Z","shell.execute_reply.started":"2023-11-15T04:03:40.754475Z","shell.execute_reply":"2023-11-15T04:03:41.691576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating an end-to-end version\nIt's no fun running our model in the current state: having to tokenize the text, pad it, call the model and then work out labels. Let's create an easy-to-use end-to-end version with our model and tokenizer.","metadata":{}},{"cell_type":"code","source":"class ExportModel():\n    def __init__(self, model, tokenizer):\n        self.model = model\n        self.tokenizer = tokenizer\n\n    def __call__(self, x):\n        if isinstance(x, str):\n            x = [x]\n\n        x = [self.tokenizer.encode(text).ids for text in x]\n        x = tf.keras.preprocessing.sequence.pad_sequences(\n            x, maxlen=sequence_length, padding='post')\n\n        pred = self.model(\n            x,\n            training=False\n        )\n\n        res = np.array([])\n\n        for p in pred:\n            label = \"POSITIVE\" if tf.keras.backend.greater(p[0], 0.5) else \"NEGATIVE\"\n            confidence = tf.keras.backend.abs(p[0] - 0.5) * 2\n\n            res = np.append(res, {\n                \"label\": label,\n                \"confidence\": confidence.numpy()\n            })\n\n        return res\n\nexport = ExportModel(model, tokenizer)\n\nwith open('/kaggle/working/model_end2end', 'wb') as f:\n    pickle.dump(export, f)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T04:03:41.694046Z","iopub.execute_input":"2023-11-15T04:03:41.694335Z","iopub.status.idle":"2023-11-15T04:03:43.403359Z","shell.execute_reply.started":"2023-11-15T04:03:41.694313Z","shell.execute_reply":"2023-11-15T04:03:43.402443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/model_end2end', 'rb') as f:\n    exported_file = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T04:03:43.404306Z","iopub.execute_input":"2023-11-15T04:03:43.404561Z","iopub.status.idle":"2023-11-15T04:03:57.583593Z","shell.execute_reply.started":"2023-11-15T04:03:43.404540Z","shell.execute_reply":"2023-11-15T04:03:57.582589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the end-to-end model","metadata":{}},{"cell_type":"code","source":"export([\"high quality\",\"exellent\",\"charge was fired\",\"surprisingly not fine\",\"horrible product\",\"trash product\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"export([\"This is a great product\", \"This is a horrible product\"]) == exported_file([\"This is a great product\", \"This is a horrible product\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T04:04:06.186782Z","iopub.execute_input":"2023-11-15T04:04:06.187090Z","iopub.status.idle":"2023-11-15T04:04:21.347521Z","shell.execute_reply.started":"2023-11-15T04:04:06.187065Z","shell.execute_reply":"2023-11-15T04:04:21.346425Z"},"trusted":true},"execution_count":null,"outputs":[]}]}